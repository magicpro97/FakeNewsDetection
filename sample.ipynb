{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T06:09:46.787221Z",
     "start_time": "2025-03-26T06:09:43.602573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# üöÄ **K√≠ch ho·∫°t GPU**\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# üöÄ **B·∫≠t Mixed Precision ƒë·ªÉ tƒÉng t·ªëc**\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# üöÄ **K√≠ch ho·∫°t XLA compiler ƒë·ªÉ tƒÉng hi·ªáu su·∫•t**\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# üî• **Load PhoBERT tokenizer v√† model**\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "phobert.trainable = False  # ‚ö° ƒê√≥ng bƒÉng PhoBERT\n",
    "\n",
    "# üöÄ **H√†m ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**\n",
    "def preprocess_data(data):\n",
    "    texts = data['Content'].tolist()\n",
    "    labels = data['Label'].tolist()\n",
    "\n",
    "    # Tokenize vƒÉn b·∫£n v·ªõi PhoBERT\n",
    "    inputs = tokenizer(texts, padding='max_length', truncation=True, max_length=256, return_tensors='tf')\n",
    "\n",
    "    return tf.convert_to_tensor(inputs['input_ids'], dtype=tf.int32), \\\n",
    "           tf.convert_to_tensor(inputs['attention_mask'], dtype=tf.int32), \\\n",
    "           tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# üî• **T·∫°o l·ªõp Keras t√πy ch·ªânh cho PhoBERT**\n",
    "class CustomPhoBERTLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, phobert_model, **kwargs):\n",
    "        super(CustomPhoBERTLayer, self).__init__(**kwargs)\n",
    "        self.phobert = phobert_model\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask = inputs\n",
    "        output = self.phobert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        return output\n",
    "\n",
    "\n",
    "# üî• **H√†m x√¢y d·ª±ng m√¥ h√¨nh PhoBERT**\n",
    "def build_model():\n",
    "    input_ids = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "    # ‚úÖ **D√πng l·ªõp CustomPhoBERTLayer thay v√¨ Lambda**\n",
    "    phobert_output = CustomPhoBERTLayer(phobert)([input_ids, attention_mask])\n",
    "\n",
    "    # üìå **L·∫•y embedding t·ª´ token ƒë·∫ßu ti√™n [CLS]**\n",
    "    text_embedding = tf.keras.layers.Lambda(lambda x: x[:, 0, :])(phobert_output)\n",
    "\n",
    "    dropout = tf.keras.layers.Dropout(0.1)(text_embedding)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# üöÄ **Load d·ªØ li·ªáu**\n",
    "real_news = pd.read_csv('./data/vnexpress_dataset.csv')\n",
    "fake_news = pd.read_csv('./data/vnexpress_fake_dataset.csv')\n",
    "\n",
    "# G√°n nh√£n\n",
    "real_news['Label'] = 0\n",
    "fake_news['Label'] = 1\n",
    "data = pd.concat([real_news, fake_news], ignore_index=True)\n",
    "\n",
    "# üöÄ **Chia th√†nh train (70%), validation (15%) v√† test (15%)**\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data['Content'], data['Label'], test_size=0.3, random_state=42, stratify=data['Label']\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    test_texts, test_labels, test_size=0.5, random_state=42, stratify=test_labels\n",
    ")\n",
    "\n",
    "# üöÄ **Tokenize d·ªØ li·ªáu**\n",
    "train_inputs, train_mask, train_labels = preprocess_data(pd.DataFrame({'Content': train_texts, 'Label': train_labels}))\n",
    "val_inputs, val_mask, val_labels = preprocess_data(pd.DataFrame({'Content': val_texts, 'Label': val_labels}))\n",
    "test_inputs, test_mask, test_labels = preprocess_data(pd.DataFrame({'Content': test_texts, 'Label': test_labels}))\n",
    "\n",
    "# üöÄ **T·∫°o dataset TensorFlow**\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({'input_ids': train_inputs, 'attention_mask': train_mask}, train_labels)) \\\n",
    "    .batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': val_inputs, 'attention_mask': val_mask}, val_labels)) \\\n",
    "    .batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({'input_ids': test_inputs, 'attention_mask': test_mask}, test_labels)) \\\n",
    "    .batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# üöÄ **Train model**\n",
    "model = build_model()\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
    "\n",
    "# üöÄ **ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test**\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ],
   "id": "9c596de0828959ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at vinai/phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at vinai/phobert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 91\u001B[39m\n\u001B[32m     86\u001B[39m val_texts, test_texts, val_labels, test_labels = train_test_split(\n\u001B[32m     87\u001B[39m     test_texts, test_labels, test_size=\u001B[32m0.5\u001B[39m, random_state=\u001B[32m42\u001B[39m, stratify=test_labels\n\u001B[32m     88\u001B[39m )\n\u001B[32m     90\u001B[39m \u001B[38;5;66;03m# üöÄ **Tokenize d·ªØ li·ªáu**\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m train_inputs, train_mask, train_labels = \u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mContent\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_texts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mLabel\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     92\u001B[39m val_inputs, val_mask, val_labels = preprocess_data(pd.DataFrame({\u001B[33m'\u001B[39m\u001B[33mContent\u001B[39m\u001B[33m'\u001B[39m: val_texts, \u001B[33m'\u001B[39m\u001B[33mLabel\u001B[39m\u001B[33m'\u001B[39m: val_labels}))\n\u001B[32m     93\u001B[39m test_inputs, test_mask, test_labels = preprocess_data(pd.DataFrame({\u001B[33m'\u001B[39m\u001B[33mContent\u001B[39m\u001B[33m'\u001B[39m: test_texts, \u001B[33m'\u001B[39m\u001B[33mLabel\u001B[39m\u001B[33m'\u001B[39m: test_labels}))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 32\u001B[39m, in \u001B[36mpreprocess_data\u001B[39m\u001B[34m(data)\u001B[39m\n\u001B[32m     29\u001B[39m labels = data[\u001B[33m'\u001B[39m\u001B[33mLabel\u001B[39m\u001B[33m'\u001B[39m].tolist()\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# Tokenize vƒÉn b·∫£n v·ªõi PhoBERT\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m inputs = \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmax_length\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m tf.convert_to_tensor(inputs[\u001B[33m'\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m'\u001B[39m], dtype=tf.int32), \\\n\u001B[32m     35\u001B[39m        tf.convert_to_tensor(inputs[\u001B[33m'\u001B[39m\u001B[33mattention_mask\u001B[39m\u001B[33m'\u001B[39m], dtype=tf.int32), \\\n\u001B[32m     36\u001B[39m        tf.convert_to_tensor(labels, dtype=tf.float32)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FakeNewsDetection\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2887\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.__call__\u001B[39m\u001B[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[39m\n\u001B[32m   2885\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._in_target_context_manager:\n\u001B[32m   2886\u001B[39m         \u001B[38;5;28mself\u001B[39m._switch_to_input_mode()\n\u001B[32m-> \u001B[39m\u001B[32m2887\u001B[39m     encodings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2888\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2889\u001B[39m     \u001B[38;5;28mself\u001B[39m._switch_to_target_mode()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FakeNewsDetection\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2947\u001B[39m, in \u001B[36mPreTrainedTokenizerBase._call_one\u001B[39m\u001B[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[39m\n\u001B[32m   2944\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   2946\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text):\n\u001B[32m-> \u001B[39m\u001B[32m2947\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2948\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2949\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2950\u001B[39m     )\n\u001B[32m   2952\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text_pair):\n\u001B[32m   2953\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2954\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2955\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2956\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T06:05:41.863371Z",
     "start_time": "2025-03-26T06:05:37.863376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# l∆∞u m√¥ h√¨nh\n",
    "model.export('./model')"
   ],
   "id": "c738aa98079604b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at './model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 256), dtype=tf.int32, name='attention_mask')]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float16, name=None)\n",
      "Captures:\n",
      "  2661833522640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661789729424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661789729232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661789730576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661789730192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662461349456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661778586320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442442320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442441360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442441744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442440976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442441936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442440592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442441168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442442896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442440784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442439824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442442512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442439440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442440016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442441552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442439632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442438096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442440400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442435408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442439056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442437520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442438864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661972227088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442438288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442440208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442437328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442442128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442438480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442439248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662442443664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505853968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505855312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505856464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505854352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505855120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505856656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505856080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505855696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505854736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505855504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505841104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505856848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505854928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505852240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505855888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505856272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662505854544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528190416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528190608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528189072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528192336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528190224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528189840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528189264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528191376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528188880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528189648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661765492048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661765491280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528189456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528191568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528188496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528190032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662528190800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832418192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832416848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832418576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832417232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832418960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832418000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832419344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832418768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832417040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832419152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832420112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832417808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832420496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832419920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832418384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832420304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832421264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832419536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832421648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832420880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832422032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832421072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832422416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832421840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832419728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832422224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832423184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832420688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832423568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832422992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832421456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832423376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832424336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832422608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832424720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832423952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832425104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832424144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832424912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832417424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832423760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832417616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832424528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832425296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832422800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833508048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833507664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833507856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833508816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833507472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833509200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833508432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833509584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833508624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833509968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833509392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833506896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833509776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833510736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833508240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833511120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833510544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833509008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833510928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833511888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833510160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833512272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833511504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833512656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833511696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833513040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833512464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833510352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833512848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833513808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833511312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833514192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833513616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833512080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833514000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833514960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833513232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833515344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833514576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833515728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833514768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833516112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833515536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833513424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833515920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833516880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833514384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833517264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833516688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833515152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833517072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833518032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833516304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833518416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833517648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833518800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833517840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833519184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833518608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833516496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833518992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833519952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833517456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833520336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833519760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833518224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833520144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833521104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833519376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833521488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833520720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833521872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833520912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833522256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833521680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833519568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833522064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833523024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833520528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833522832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833507280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833522448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833507088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661833521296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2661832593808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2662507436880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
